<!doctype html>
<html>
<head>

<!-- Font awesome -->
<script src="https://kit.fontawesome.com/4e7b256b76.js" crossorigin="anonymous"></script>

<!-- Required meta tags -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<!-- Fonts -->
<link href="https://fonts.googleapis.com/css2?family=Calistoga&family=Langar&family=Sacramento&display=swap" rel="stylesheet">
<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Cabin&display=swap" rel="stylesheet">
<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Special+Elite&display=swap" rel="stylesheet">

<!-- Bootstrap CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">


<title>Background of Fake News</title>

</head>
<link rel="stylesheet" href="css/styles.css">
<link rel="icon" href="favicon.ico">
<link href="https://fonts.googleapis.com/css2?family=Calistoga&family=Langar&family=Sacramento&display=swap" rel="stylesheet">

<body class="main-content text-body">
<section id="header">
<div id="wrapper">
<header>  <!-- Begnning of header -->
<!-- <img src="images/Realism.jpg" alt="Fake news logo" /> -->

  <nav class="navbar navbar-expand-lg bg-info navbar-dark">  <!--Beginning of Navigation -->
    <a class="navbar-brand" href="index.html">Fake News</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav ml-auto">
      <li class="nav-item"><a class="nav-link" href="index.html"> Home</a></li>
      <!-- <li class="nav-item"><a class="nav-link" href="latest-news.html"> Trending News</a></li> -->
      <li class="nav-item"><a class="nav-link" href="videos.html"> Videos </a></li>
      <li class="nav-item"><a class="nav-link" href="about.html"> About</a></li>
      <li class="nav-item"><a class="nav-link" href="Contact_us.html"> Contact Us</a></li>
      <!-- <li class="nav-item"><a class="nav-link" href=""> Sign in</a></li>
      <li class="nav-item"><a class="nav-link" href=""> Sign Up</a></li> -->
      <!-- <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
          More
        </a>
        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
          <a class="dropdown-item" href="alumni.html">Alumni</a>
          <a class="dropdown-item" href="faq.html">FAQ</a>
          <div class="dropdown-divider"></div>
          <a class="dropdown-item" href="lesson.html">Lesson</a>
        </div>
      </li> -->
      <form class="form-inline">
    <input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search">
    <button class="btn btn-outline-success my-2 my-sm-0" type="submit" >Search</button>
  </form>
    </ul>
    </div>
  </nav> <!--End of navigation-->

   </header> <!-- End of Header -->
</div> <!--end of wrapper-->
</section>


<h1 class="header-top">Foundation of Fake News</h1>
<section class="header-body">
  <h1 class="steps">
    The Psychology of Fake News
  </h1>
  <p>
    Most of us do not witness news events first hand, nor do we have direct exposure to
the workings of politics. Instead, we rely on accounts of others; much of what we
claim to know is actually distributed knowledge that has been acquired, stored, and
transmitted by others. Likewise, much of our decision-making stems not from
individual rationality but from shared group-level narratives (Sloman &
Fernbach, 2017). As a result, our receptivity to information and misinformation
depends less than we might expect on rational evaluation and more on the
heuristics and social processes we describe below.
  </p>

  <p>
    First, source credibility profoundly affects the social interpretation of
information (Swire et al., 2017; Metzger et al., 2010; Berinsky, 2017, Baum and
Groeling 2009; Greenhill and Oppenheim, n.d.). Individuals trust information
coming from well-known or familiar sources and from sources that align with their
worldview. Second, humans are biased information-seekers: we prefer to receive
information that confirms our existing views. These properties combine to make
people asymmetric updaters about political issues (Sunstein et al., 2016).
Individuals tend to accept new information uncritically when a source is perceived
as credible or the information confirms prior views. And when the information is
unfamiliar or comes from an opposition source, it may be ignored.
  </p>

  <p>
    As a result, correcting misinformation does not necessarily change people’s
beliefs (Nyhan and Reifler, 2010; Flynn et al., 2016). In fact, presenting people with
challenging information can even backfire, further entrenching people in their
initial beliefs. However, even when an individual believes the correction, the
misinformation may persist. An important implication of this point is that any
repetition of misinformation, even in the context of refuting it, can be harmful
(Thorson, 2015, Greenhill and Oppenheim, forthcoming). This persistence is due to
familiarity and fluency biases in our cognitive processing: the more an individual
hears a story, the more familiar it becomes, and the more likely the individual is to
believe it as true (Hasher et al 1977; Schwartz et al, 2007; Pennycook et al., n.d.). As a
result, exposure to misinformation can have long-term effects, while corrections
may be short-lived.
  </p>

  <p>
    One factor that does affect the acceptance of information is social pressure.
Much of people’s behavior stems from social signaling and reputation preservation.
Therefore, there is a real threat of embarrassment for sharing news that one’s peers
perceive as fake. This threat provides an opening for fact-checking tools on social
media, such as a pop-up warning under development by Facebook. This tool does
seem to decrease sharing of disputed articles, but it is unlikely to have a lasting
effect on beliefs (Schwartz et al, 2007; Pennycook et al., n.d.). While such tools
provide a mechanism to signal that an individual is sharing fake news to their
existing peers, another opportunity for intervention is to shift peer consumption
7
online. Encouraging communication with people who are dissimilar might be an
effective way to reduce polarization and fact distortion around political issues.
  </p>

  <h1 class="steps">
    How Fake News Spreads
  </h1>

  <p>
    Fake news spreads from sources to consumers through a complex ecosystem of
websites, social media, and bots. Features that make social media engaging,
including the ease of sharing and rewiring social connections, facilitate their
manipulation by highly active and partisan individuals (and bots) that become
powerful sources of misinformation (Menczer, 2016).
  </p>

  <p>
    Fake news spreads from sources to consumers through a complex ecosystem of
websites, social media, and bots. Features that make social media engaging,
including the ease of sharing and rewiring social connections, facilitate their
manipulation by highly active and partisan individuals (and bots) that become
powerful sources of misinformation (Menczer, 2016).
  </p>

  <p>
    Even if individuals prefer to share high-quality information, limited individual
attention and information overload prevent social networks from
discriminating between messages on the basis of quality at the system level,
allowing low-quality information to spread as virally as high-quality information
(Qiu et al., 2017). This helps explain higher exposure to fake news online.
  </p>

  <p>
    It is possible to leverage structural, temporal, content, and user features to detect
social bots (Varol et al., 2017). This reveals that social bots can become quite
influential (Ferrara et al., 2016). Bots are designed to amplify the reach of fake
news (Shao et al., 2016) and exploit the vulnerabilities that stem from our
cognitive and social biases. For example, they create the appearance of popular
grassroots campaigns to manipulate attention, and target influential users to induce
them to reshare misinformation (Ratkiewicz et al., 2011).
  </p>

  <p>
    On Twitter, fake news shared by real people is concentrated in a small set of
websites and highly active “cyborg” users (Lazer, n.d.). These users automatically
share news from a set of sources (with or without reading them). Unlike traditional
elites, these individuals sometimes wield limited socio-political capital but rather
leverage their knowledge of platform affordances to grow a following around
polarized and misinformative content. These individuals can, however, attempt to
get the attention of political elites with the aid of social bots. For example, Donald
Trump received hundreds of tweets, mostly from bots, with links to the fake news
story that three million illegal immigrants voted in the election. This demonstrates
how the power dynamics on social media can, in some cases, be reversed, leading
misinformation to flow from lower status individuals to elites.
  </p>

  <p>
    Contrary to popular intuition, both fake and real information, including news,
is not often “viral” in the implied sense of spreading through long information
cascades (Goel, Sharad, et al., 2015). That is, the vast majority of shared content
does not spread in long cascades among average people. It’s often messages from
celebrities and media sources—accounts with high numbers of followers—that
increase reach the most, and do so via very shallow diffusion chains. Thus,
traditional elites may not be the largest sharers of fake news content but may be the
most important node capable of stemming its spread (Greenhill and Oppenheim,
n.d.).
  </p>

  <p>
    Most people who share fake news, whether it gains popularity or not, share lots
of news in general. Volume of political activity is by far the strongest predictor of
whether an individual will share a fake news story. The fact that misinformation is
mixed with other content and that many stories get little attention from people
means that traditional measures of quality cannot distinguish misinformation from
truth (Metzger et al., 2010). Beyond this, certain characteristics of people are
associated with greater likelihood of sharing fake news: older and more extreme
individuals on the political spectrum appear to share fake news more than others
(Lazer et al., n.d.).
  </p>

  <p>
    Nation-states and politically-motivated organizations have long been the initial
brokers of misinformation. Both contemporary and historical evidence suggests
that the spread of impactful misinformation is rarely due to simple
misunderstandings. Rather, misinformation is often the result of orchestrated and
strategic campaigns that serve a particular political or military goal (Greenhill,
forthcoming). For instance, the British waged an effective campaign of fake news
around alleged German atrocities during WWI in order to mobilize domestic and
global public opinion against Germany. These efforts, however, boomeranged
during WWII, because memories of that fake news led to public skepticism, during
WWII, of reports of mass murder (Schudson, 1997).
  </p>

  <p>
    We must also acknowledge that a focus on impartiality is relatively new to how
news is reported. Historically, it was not until the early 20th century that modern
journalistic norms of fact-checking and impartiality began to take shape in the
United States. It was a wide backlash against “yellow journalism”—sensationalist
reporting styles that were spread by the 1890s newspaper empires of Hearst and
Pulitzer—that pushed journalism to begin to professionalize and institute codes of
ethics (Schudson, 2001).
  </p>

  <p>
    Finally, while any group can come to believe false information, misinformation is
currently predominantly a pathology of the right, and extreme voices from the
right have been continuously attacking the mainstream media (Benkler et al., 2017).
As a result, some conservative voters are even suspicious of fact-checking sites
(Allcott and Gentzkow, 2017). This leaves them particularly susceptible to
misinformation, which is being produced and repeated, in fact, by those same
extreme voices. That said, there is at least anecdotal evidence that when
Republicans are in power, the left becomes increasingly susceptible to promoting
9
and accepting fake news. A case in point is a conspiracy theory, spread principally
by the left during the Bush Administration, that the government was responsible for
9/11. This suggests that we may expect to witness a rise in left-wing-promulgated
fake news over the next several years. Regardless, any solutions for combating fake
news must take such asymmetry into account; different parts of the political
spectrum are affected in different ways and will need to assume different roles to
counter it.
  </p>


  <ul>
    <strong><em>References</em></strong>
    <li><p>Lazer, D., Baum, M., Grinberg, N., Friedland, L., Joseph, K., Hobbs, W., Mattsson, C., Benkler, Y., Berinsky, A., Boaden, H., Brown, K., Metzger, M., Barbara, S., Nyhan, B., Pariser, E., Pennycook, G., Robertson, L., Rothschild, D., Sloman, S. and Sunstein, C. (2017).</li> <p>Combating Fake News: An Agenda for Research and Action Sponsored by Final report written by Drawn from presentations by. [online] .
  </p>
    <p>
      Available at: <a href="https://shorensteincenter.org/wp-content/uploads/2017/05/Combating-Fake-News-Agenda-for-Research-1.pdf">Combating Fake News Agenda for Research</a> [Accessed 15 Sep. 2019]
    </p>
    </p>
  </ul>

</section>


    <section>
      <footer id="footer">
        <div class="container-fluid">

          <!-- <i class="fab fa-twitter footer-icon" id="twitter"></i>
          <i class="fab fa-instagram footer-icon" id="instagram"></i>
          <i class="fas fa-envelope footer-icon" id="envelope"></i>
          <i class="fab fa-youtube footer-icon" id="youtube"></i> -->

              <a href="https://www.facebook.com/cityofwestminstercollege/"> <i class="fab fa-facebook footer-icon" id="facebook"></i> </a>
              <a href="https://twitter.com/citywestcollege?s=20"><i class="fab fa-twitter footer-icon" id="twitter"></i></a>
              <a href="https://www.instagram.com/citywestcollege/?hl=en"><i class="fab fa-instagram footer-icon" id="instagram"></i></a>
              <a href="https://www.youtube.com/user/citywestcollege"><i class="fab fa-youtube footer-icon" id="youtube"></i></a>
              <a href="Contact_us.html"><i class="fas fa-envelope footer-icon" id="envelope"></i></a>
              <a href="https://forms.office.com/Pages/DesignPage.aspx?auth_pvr=OrgId&auth_upn=195343%40my.cwc.ac.uk&origin=OfficeDotCom&lang=en-US&route=Start#FormId=z_TxBDtR40eWbxDWaYyjGj7D7HCnTWNIjheI7x-qHuxUNVA4MlY5NFoxWjhZUjNQMEI0Vlo5WFBSRy4u"><i class="fas fa-comments footer-icon" id="f-form"></i></a>


          <p id="copyright">© Copyright 2021 John Adeyemi</p>
        </div>


      </footer>
    </section>


    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    </body>




    <!-- BEGINNING OF OBSOLETE CODE-->

    <!-- <section>
      <div id="form"> -->
        <!-- <iframe width="600px" height= "400px" src= "https://forms.office.com/Pages/ResponsePage.aspx?id=z_TxBDtR40eWbxDWaYyjGj7D7HCnTWNIjheI7x-qHuxUOU9VWDUxQlRZQTgzQ0w3VFlTUjA4OTkzNC4u&embed=true" frameborder= "0" marginwidth= "0" marginheight= "0" style= "border: none; max-width:100%; max-height:100vh" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe> -->
      <!-- </div>
    </section> -->



    <!-- <div class="contianer-fluid" >

    </div> -->

    <!-- END OF OBSOLETE CODE-->

    </html>
